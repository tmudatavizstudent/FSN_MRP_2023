{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1356,
   "id": "acc97f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Median Price</th>\n",
       "      <th>CPI_Can</th>\n",
       "      <th>Inflation</th>\n",
       "      <th>Bank_Rate</th>\n",
       "      <th>CAN_Mort_Lending_Rate5yr</th>\n",
       "      <th>Mortgage_Var_Rate</th>\n",
       "      <th>Mortgage_Fixed_Rate_5yr</th>\n",
       "      <th>Bond_1-3yr_Avg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>413500</td>\n",
       "      <td>121.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.25</td>\n",
       "      <td>4.14</td>\n",
       "      <td>3.57</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-01</th>\n",
       "      <td>434000</td>\n",
       "      <td>122.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.25</td>\n",
       "      <td>4.11</td>\n",
       "      <td>3.52</td>\n",
       "      <td>2.98</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-01</th>\n",
       "      <td>441000</td>\n",
       "      <td>122.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.25</td>\n",
       "      <td>4.02</td>\n",
       "      <td>3.51</td>\n",
       "      <td>2.99</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-01</th>\n",
       "      <td>453500</td>\n",
       "      <td>122.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.25</td>\n",
       "      <td>4.02</td>\n",
       "      <td>3.52</td>\n",
       "      <td>2.99</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-01</th>\n",
       "      <td>478500</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.25</td>\n",
       "      <td>4.02</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.96</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>797500</td>\n",
       "      <td>153.9</td>\n",
       "      <td>6.4</td>\n",
       "      <td>4.50</td>\n",
       "      <td>5.86</td>\n",
       "      <td>6.31</td>\n",
       "      <td>5.25</td>\n",
       "      <td>3.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-01</th>\n",
       "      <td>850000</td>\n",
       "      <td>154.5</td>\n",
       "      <td>6.2</td>\n",
       "      <td>4.75</td>\n",
       "      <td>5.81</td>\n",
       "      <td>6.35</td>\n",
       "      <td>5.14</td>\n",
       "      <td>4.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-01</th>\n",
       "      <td>850000</td>\n",
       "      <td>155.3</td>\n",
       "      <td>5.9</td>\n",
       "      <td>4.75</td>\n",
       "      <td>5.81</td>\n",
       "      <td>6.59</td>\n",
       "      <td>5.09</td>\n",
       "      <td>3.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-01</th>\n",
       "      <td>875000</td>\n",
       "      <td>156.4</td>\n",
       "      <td>5.7</td>\n",
       "      <td>4.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>6.65</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-01</th>\n",
       "      <td>928800</td>\n",
       "      <td>157.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>4.75</td>\n",
       "      <td>5.74</td>\n",
       "      <td>6.81</td>\n",
       "      <td>4.95</td>\n",
       "      <td>3.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Median Price  CPI_Can  Inflation  Bank_Rate  \\\n",
       "Month                                                     \n",
       "2013-01-01        413500    121.3        1.3       1.25   \n",
       "2013-02-01        434000    122.7        1.5       1.25   \n",
       "2013-03-01        441000    122.9        1.5       1.25   \n",
       "2013-04-01        453500    122.7        1.2       1.25   \n",
       "2013-05-01        478500    123.0        1.2       1.25   \n",
       "...                  ...      ...        ...        ...   \n",
       "2023-01-01        797500    153.9        6.4       4.50   \n",
       "2023-02-01        850000    154.5        6.2       4.75   \n",
       "2023-03-01        850000    155.3        5.9       4.75   \n",
       "2023-04-01        875000    156.4        5.7       4.75   \n",
       "2023-05-01        928800    157.0        5.2       4.75   \n",
       "\n",
       "            CAN_Mort_Lending_Rate5yr  Mortgage_Var_Rate  \\\n",
       "Month                                                     \n",
       "2013-01-01                      4.14               3.57   \n",
       "2013-02-01                      4.11               3.52   \n",
       "2013-03-01                      4.02               3.51   \n",
       "2013-04-01                      4.02               3.52   \n",
       "2013-05-01                      4.02               3.50   \n",
       "...                              ...                ...   \n",
       "2023-01-01                      5.86               6.31   \n",
       "2023-02-01                      5.81               6.35   \n",
       "2023-03-01                      5.81               6.59   \n",
       "2023-04-01                      5.75               6.65   \n",
       "2023-05-01                      5.74               6.81   \n",
       "\n",
       "            Mortgage_Fixed_Rate_5yr  Bond_1-3yr_Avg  \n",
       "Month                                                \n",
       "2013-01-01                     3.00            1.16  \n",
       "2013-02-01                     2.98            1.12  \n",
       "2013-03-01                     2.99            1.01  \n",
       "2013-04-01                     2.99            1.00  \n",
       "2013-05-01                     2.96            1.04  \n",
       "...                             ...             ...  \n",
       "2023-01-01                     5.25            3.83  \n",
       "2023-02-01                     5.14            4.09  \n",
       "2023-03-01                     5.09            3.87  \n",
       "2023-04-01                     5.00            3.73  \n",
       "2023-05-01                     4.95            3.95  \n",
       "\n",
       "[125 rows x 8 columns]"
      ]
     },
     "execution_count": 1356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "df = pd.read_csv('lstm_data.csv', index_col='Month', parse_dates=True)\n",
    "df = df[['Median Price', 'CPI_Can', 'Inflation', 'Bank_Rate', 'CAN_Mort_Lending_Rate5yr', 'Mortgage_Var_Rate', 'Mortgage_Fixed_Rate_5yr', 'Bond_1-3yr_Avg']]   \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c6702c",
   "metadata": {},
   "source": [
    "## SINGLE STEP LSTM w EXO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1233,
   "id": "4df4e159",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "from tensorflow.random import set_seed\n",
    "\n",
    "seed(1)\n",
    "set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1357,
   "id": "a9d86ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 2s 52ms/step - loss: 0.2341\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1580\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0947\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0461\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0157\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0140\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0252\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0323\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0275\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0184\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0114\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0088\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0100\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0120\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0130\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0124\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0108\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0091\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0080\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0080\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0084\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0088\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0087\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0083\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0078\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0075\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0078\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0079\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0080\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0079\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0076\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0076\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0074\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0074\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0075\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0075\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0074\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0073\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0073\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0073\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0073\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0072\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0072\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0072\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0071\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0071\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0071\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0071\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0070\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0070\n",
      "1/1 [==============================] - 1s 582ms/step\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "\n",
    "window_size = 60\n",
    "X, y = [], []\n",
    "for i in range(window_size, len(scaled_data)):\n",
    "    X.append(scaled_data[i-window_size:i])\n",
    "    y.append(scaled_data[i, 0])\n",
    "X, y = np.array(X), np.array(y)\n",
    "\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(20, return_sequences=True, input_shape=(window_size, X.shape[2])))\n",
    "model.add(LSTM(20))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32)\n",
    " \n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1163,
   "id": "100107ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_329\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_649 (LSTM)             (None, 48, 20)            2320      \n",
      "                                                                 \n",
      " lstm_650 (LSTM)             (None, 20)                3280      \n",
      "                                                                 \n",
      " dense_336 (Dense)           (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,621\n",
      "Trainable params: 5,621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1203,
   "id": "cd37d293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([802515.98128676, 803848.45641255, 805207.70800114])"
      ]
     },
     "execution_count": 1203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict Q1 of 2021 ST X\n",
    "start_date = '2021-01-01'\n",
    "end_date = '2021-03-01'\n",
    "dates = pd.date_range(start_date, end_date, freq='MS')\n",
    "X = []\n",
    "for date in dates:\n",
    "    past_data = df.loc[date - pd.DateOffset(months=window_size):date - pd.DateOffset(months=1)]\n",
    "    past_data = scaler.transform(past_data)\n",
    "    X.append(past_data)\n",
    "X = np.array(X)\n",
    "y_pred_2021Q1 = model.predict(X)\n",
    "y_pred_orig_2021Q1 = np.zeros((len(y_pred_2021Q1), df.shape[1]))\n",
    "y_pred_orig_2021Q1[:, 0] = y_pred_2021Q1[:, 0]\n",
    "y_pred_orig_2021Q1 = scaler.inverse_transform(y_pred_orig_2021Q1)[:, 0]\n",
    "y_pred_orig_2021Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1210,
   "id": "5db1bbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([829469.78327632, 835054.92120981, 841444.26470995])"
      ]
     },
     "execution_count": 1210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict Q2 of 2021 ST X\n",
    "start_date = '2021-04-01'\n",
    "end_date = '2021-06-01'\n",
    "dates = pd.date_range(start_date, end_date, freq='MS')\n",
    "X = []\n",
    "for date in dates:\n",
    "    past_data = df.loc[date - pd.DateOffset(months=window_size):date - pd.DateOffset(months=1)]\n",
    "    past_data = scaler.transform(past_data)\n",
    "    X.append(past_data)\n",
    "X = np.array(X)\n",
    "y_pred_2021Q2 = model.predict(X)\n",
    "y_pred_orig_2021Q2 = np.zeros((len(y_pred_2021Q2), df.shape[1]))\n",
    "y_pred_orig_2021Q2[:, 0] = y_pred_2021Q2[:, 0]\n",
    "y_pred_orig_2021Q2 = scaler.inverse_transform(y_pred_orig_2021Q2)[:, 0]\n",
    "y_pred_orig_2021Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1241,
   "id": "b49eb365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([822578.98044586, 829817.87729263, 836728.09559107])"
      ]
     },
     "execution_count": 1241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict Q3 of 2021 ST X\n",
    "start_date = '2021-07-01'\n",
    "end_date = '2021-09-01'\n",
    "dates = pd.date_range(start_date, end_date, freq='MS')\n",
    "X = []\n",
    "for date in dates:\n",
    "    past_data = df.loc[date - pd.DateOffset(months=window_size):date - pd.DateOffset(months=1)]\n",
    "    past_data = scaler.transform(past_data)\n",
    "    X.append(past_data)\n",
    "X = np.array(X)\n",
    "y_pred_2021Q3 = model.predict(X)\n",
    "y_pred_orig_2021Q3 = np.zeros((len(y_pred_2021Q3), df.shape[1]))\n",
    "y_pred_orig_2021Q3[:, 0] = y_pred_2021Q3[:, 0]\n",
    "y_pred_orig_2021Q3 = scaler.inverse_transform(y_pred_orig_2021Q3)[:, 0]\n",
    "y_pred_orig_2021Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1358,
   "id": "02283062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([859592.08834171, 864564.67670202, 868874.64046478])"
      ]
     },
     "execution_count": 1358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict Q4 of 2021 ST X\n",
    "start_date = '2021-10-01'\n",
    "end_date = '2021-12-01'\n",
    "dates = pd.date_range(start_date, end_date, freq='MS')\n",
    "X = []\n",
    "for date in dates:\n",
    "    past_data = df.loc[date - pd.DateOffset(months=window_size):date - pd.DateOffset(months=1)]\n",
    "    past_data = scaler.transform(past_data)\n",
    "    X.append(past_data)\n",
    "X = np.array(X)\n",
    "y_pred_2021Q4 = model.predict(X)\n",
    "y_pred_orig_2021Q4 = np.zeros((len(y_pred_2021Q4), df.shape[1]))\n",
    "y_pred_orig_2021Q4[:, 0] = y_pred_2021Q4[:, 0]\n",
    "y_pred_orig_2021Q4 = scaler.inverse_transform(y_pred_orig_2021Q4)[:, 0]\n",
    "y_pred_orig_2021Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1168,
   "id": "f1fc97f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict the entire year of 2021\n",
    "start_date = '2021-01-01'\n",
    "end_date = '2021-12-01'\n",
    "dates = pd.date_range(start_date, end_date, freq='MS')\n",
    "X = []\n",
    "for date in dates:\n",
    "    past_data = df.loc[date - pd.DateOffset(months=window_size):date - pd.DateOffset(months=1)]\n",
    "    past_data = scaler.transform(past_data)\n",
    "    X.append(past_data)\n",
    "X = np.array(X)\n",
    "y_pred_2021 = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1169,
   "id": "67b15c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([803916.59626365, 803671.08345032, 803346.55812383, 805273.24786782,\n",
       "       808948.00505042, 814370.32318115, 820209.58426595, 825938.12653422,\n",
       "       831060.9062016 , 836739.20461535, 843128.04162502, 849765.59922099])"
      ]
     },
     "execution_count": 1169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_orig_2021 = np.zeros((len(y_pred_2021), df.shape[1]))\n",
    "y_pred_orig_2021[:, 0] = y_pred_2021[:, 0]\n",
    "y_pred_orig_2021 = scaler.inverse_transform(y_pred_orig_2021)[:, 0]\n",
    "y_pred_orig_2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1029,
   "id": "49b7cde8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict the entire year of 2020\n",
    "start_date = '2020-01-01'\n",
    "end_date = '2020-12-01'\n",
    "dates = pd.date_range(start_date, end_date, freq='MS')\n",
    "X = []\n",
    "for date in dates:\n",
    "    past_data = df.loc[date - pd.DateOffset(months=window_size):date - pd.DateOffset(months=1)]\n",
    "    past_data = scaler.transform(past_data)\n",
    "    X.append(past_data)\n",
    "X = np.array(X)\n",
    "y_pred_2020 = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1030,
   "id": "1c666a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([760792.10683703, 773429.48299646, 783418.48802567, 790965.73626995,\n",
       "       793230.39022088, 792276.16217732, 792696.07654214, 796030.33706546,\n",
       "       801289.32890296, 803249.48078394, 805664.25850987, 809774.25983548])"
      ]
     },
     "execution_count": 1030,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_orig_2020 = np.zeros((len(y_pred_2020), df.shape[1]))\n",
    "y_pred_orig_2020[:, 0] = y_pred_2020[:, 0]\n",
    "y_pred_orig_2020 = scaler.inverse_transform(y_pred_orig_2020)[:, 0]\n",
    "y_pred_orig_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1079,
   "id": "f1c0dd35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict the entire year of 2022\n",
    "start_date = '2022-01-01'\n",
    "end_date = '2022-12-01'\n",
    "dates = pd.date_range(start_date, end_date, freq='MS')\n",
    "X = []\n",
    "for date in dates:\n",
    "    past_data = df.loc[date - pd.DateOffset(months=window_size):date - pd.DateOffset(months=1)]\n",
    "    past_data = scaler.transform(past_data)\n",
    "    X.append(past_data)\n",
    "X = np.array(X)\n",
    "y_pred_2020 = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1080,
   "id": "b7a98f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([860519.84381676, 872281.59925342, 879955.0986886 , 884050.04036427,\n",
       "       889448.41837883, 895714.04314041, 903313.49366903, 911462.65518665,\n",
       "       918811.3591671 , 920328.1968236 , 920625.43919682, 922170.74161768])"
      ]
     },
     "execution_count": 1080,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_orig_2022 = np.zeros((len(y_pred_2022), df.shape[1]))\n",
    "y_pred_orig_2022[:, 0] = y_pred_2022[:, 0]\n",
    "y_pred_orig_2022 = scaler.inverse_transform(y_pred_orig_2022)[:, 0]\n",
    "y_pred_orig_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1313,
   "id": "ef2dd0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([865908.53098035, 870940.68261981, 877222.61637449])"
      ]
     },
     "execution_count": 1313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict Q1 of 2022 ST X\n",
    "start_date = '2022-01-01'\n",
    "end_date = '2022-03-01'\n",
    "dates = pd.date_range(start_date, end_date, freq='MS')\n",
    "X = []\n",
    "for date in dates:\n",
    "    past_data = df.loc[date - pd.DateOffset(months=window_size):date - pd.DateOffset(months=1)]\n",
    "    past_data = scaler.transform(past_data)\n",
    "    X.append(past_data)\n",
    "X = np.array(X)\n",
    "y_pred_2022Q1 = model.predict(X)\n",
    "y_pred_orig_2022Q1 = np.zeros((len(y_pred_2022Q1), df.shape[1]))\n",
    "y_pred_orig_2022Q1[:, 0] = y_pred_2022Q1[:, 0]\n",
    "y_pred_orig_2022Q1 = scaler.inverse_transform(y_pred_orig_2022Q1)[:, 0]\n",
    "y_pred_orig_2022Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1351,
   "id": "a2bd3f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([919890.21763206, 928233.70265961, 936934.46606398])"
      ]
     },
     "execution_count": 1351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict Q2 of 2022 ST X\n",
    "start_date = '2022-04-01'\n",
    "end_date = '2022-06-01'\n",
    "dates = pd.date_range(start_date, end_date, freq='MS')\n",
    "X = []\n",
    "for date in dates:\n",
    "    past_data = df.loc[date - pd.DateOffset(months=window_size):date - pd.DateOffset(months=1)]\n",
    "    past_data = scaler.transform(past_data)\n",
    "    X.append(past_data)\n",
    "X = np.array(X)\n",
    "y_pred_2022Q2 = model.predict(X)\n",
    "y_pred_orig_2022Q2 = np.zeros((len(y_pred_2022Q2), df.shape[1]))\n",
    "y_pred_orig_2022Q2[:, 0] = y_pred_2022Q2[:, 0]\n",
    "y_pred_orig_2022Q2 = scaler.inverse_transform(y_pred_orig_2022Q2)[:, 0]\n",
    "y_pred_orig_2022Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1348,
   "id": "1d80b96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([867046.91895843, 865024.84017611, 861569.32583451])"
      ]
     },
     "execution_count": 1348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict Q3 of 2022 ST X\n",
    "start_date = '2022-07-01'\n",
    "end_date = '2022-09-01'\n",
    "dates = pd.date_range(start_date, end_date, freq='MS')\n",
    "X = []\n",
    "for date in dates:\n",
    "    past_data = df.loc[date - pd.DateOffset(months=window_size):date - pd.DateOffset(months=1)]\n",
    "    past_data = scaler.transform(past_data)\n",
    "    X.append(past_data)\n",
    "X = np.array(X)\n",
    "y_pred_2022Q3 = model.predict(X)\n",
    "y_pred_orig_2022Q3 = np.zeros((len(y_pred_2022Q3), df.shape[1]))\n",
    "y_pred_orig_2022Q3[:, 0] = y_pred_2022Q3[:, 0]\n",
    "y_pred_orig_2022Q3 = scaler.inverse_transform(y_pred_orig_2022Q3)[:, 0]\n",
    "y_pred_orig_2022Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1317,
   "id": "900f7a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([898562.34294176, 894881.60917163, 890866.0852015 ])"
      ]
     },
     "execution_count": 1317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict Q4 of 2022 ST X\n",
    "start_date = '2022-10-01'\n",
    "end_date = '2022-12-01'\n",
    "dates = pd.date_range(start_date, end_date, freq='MS')\n",
    "X = []\n",
    "for date in dates:\n",
    "    # Get the past window_size values for all variables\n",
    "    past_data = df.loc[date - pd.DateOffset(months=window_size):date - pd.DateOffset(months=1)]\n",
    "    past_data = scaler.transform(past_data)\n",
    "    X.append(past_data)\n",
    "X = np.array(X)\n",
    "y_pred_2022Q4 = model.predict(X)\n",
    "y_pred_orig_2022Q4 = np.zeros((len(y_pred_2022Q4), df.shape[1]))\n",
    "y_pred_orig_2022Q4[:, 0] = y_pred_2022Q4[:, 0]\n",
    "y_pred_orig_2022Q4 = scaler.inverse_transform(y_pred_orig_2022Q4)[:, 0]\n",
    "y_pred_orig_2022Q4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fe27d8",
   "metadata": {},
   "source": [
    "## single step without exo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1360,
   "id": "134f8773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Median Price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>413500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-01</th>\n",
       "      <td>434000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-01</th>\n",
       "      <td>441000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-01</th>\n",
       "      <td>453500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-01</th>\n",
       "      <td>478500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>797500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-01</th>\n",
       "      <td>850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-01</th>\n",
       "      <td>850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-01</th>\n",
       "      <td>875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-01</th>\n",
       "      <td>928800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Median Price\n",
       "Month                   \n",
       "2013-01-01        413500\n",
       "2013-02-01        434000\n",
       "2013-03-01        441000\n",
       "2013-04-01        453500\n",
       "2013-05-01        478500\n",
       "...                  ...\n",
       "2023-01-01        797500\n",
       "2023-02-01        850000\n",
       "2023-03-01        850000\n",
       "2023-04-01        875000\n",
       "2023-05-01        928800\n",
       "\n",
       "[125 rows x 1 columns]"
      ]
     },
     "execution_count": 1360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('lstm_data.csv', index_col='Month', parse_dates=True)\n",
    "df2 = df2[['Median Price']]   \n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1361,
   "id": "82a56976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 2s 51ms/step - loss: 0.4243\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.3183\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2322\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1601\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0961\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0492\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0174\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0091\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0177\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0305\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0335\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0267\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0176\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0113\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0088\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0095\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0114\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0129\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0134\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0129\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0116\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0103\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0092\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0089\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0089\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0092\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0093\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0092\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0090\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0086\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0087\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0084\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0084\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0084\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0084\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0083\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0082\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0082\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.0081\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0080\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0080\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0079\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0079\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0079\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0078\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0077\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0077\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0077\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0076\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0076\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdf2f38caf0>"
      ]
     },
     "execution_count": 1361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df2)\n",
    "\n",
    "window_size = 60\n",
    "X, y = [], []\n",
    "for i in range(window_size, len(scaled_data)):\n",
    "    X.append(scaled_data[i-window_size:i, 0])\n",
    "    y.append(scaled_data[i, 0])\n",
    "X, y = np.array(X), np.array(y)\n",
    "X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(20, return_sequences=True, input_shape=(window_size, 1)))\n",
    "model.add(LSTM(20))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1320,
   "id": "d60eb0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 494ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([838510.13165712, 840783.63230824, 844267.94907451])"
      ]
     },
     "execution_count": 1320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict Q1 of 2022 ST no X\n",
    "start_date = '2022-01-01'\n",
    "end_date = '2022-03-01'\n",
    "dates = pd.date_range(start_date, end_date, freq='MS')\n",
    "X = []\n",
    "for date in dates:\n",
    "    past_data = df2.loc[date - pd.DateOffset(months=window_size):date - pd.DateOffset(months=1)]\n",
    "    past_data = scaler.transform(past_data)\n",
    "    X.append(past_data)\n",
    "X = np.array(X)\n",
    "y_pred_2022Q1 = model.predict(X)\n",
    "y_pred_orig_2022Q1 = np.zeros((len(y_pred_2022Q1), df2.shape[1]))\n",
    "y_pred_orig_2022Q1[:, 0] = y_pred_2022Q1[:, 0]\n",
    "y_pred_orig_2022Q1 = scaler.inverse_transform(y_pred_orig_2022Q1)[:, 0]\n",
    "y_pred_orig_2022Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1322,
   "id": "e2c895fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([849214.26746249, 855270.88049054, 862108.23169351])"
      ]
     },
     "execution_count": 1322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict Q2 of 2022 ST no X\n",
    "start_date = '2022-04-01'\n",
    "end_date = '2022-06-01'\n",
    "dates = pd.date_range(start_date, end_date, freq='MS')\n",
    "X = []\n",
    "for date in dates:\n",
    "    past_data = df2.loc[date - pd.DateOffset(months=window_size):date - pd.DateOffset(months=1)]\n",
    "    past_data = scaler.transform(past_data)\n",
    "    X.append(past_data)\n",
    "X = np.array(X)\n",
    "y_pred_2022Q2 = model.predict(X)\n",
    "y_pred_orig_2022Q2 = np.zeros((len(y_pred_2022Q2), df2.shape[1]))\n",
    "y_pred_orig_2022Q2[:, 0] = y_pred_2022Q2[:, 0]\n",
    "y_pred_orig_2022Q2 = scaler.inverse_transform(y_pred_orig_2022Q2)[:, 0]\n",
    "y_pred_orig_2022Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1355,
   "id": "b76e7a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 521ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([873483.56866837, 878611.75090075, 881744.32691932])"
      ]
     },
     "execution_count": 1355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict Q3 of 2022 ST no X\n",
    "start_date = '2022-07-01'\n",
    "end_date = '2022-09-01'\n",
    "dates = pd.date_range(start_date, end_date, freq='MS')\n",
    "X = []\n",
    "for date in dates:\n",
    "    past_data = df2.loc[date - pd.DateOffset(months=window_size):date - pd.DateOffset(months=1)]\n",
    "    past_data = scaler.transform(past_data)\n",
    "    X.append(past_data)\n",
    "X = np.array(X)\n",
    "y_pred_2022Q3 = model.predict(X)\n",
    "y_pred_orig_2022Q3 = np.zeros((len(y_pred_2022Q3), df2.shape[1]))\n",
    "y_pred_orig_2022Q3[:, 0] = y_pred_2022Q3[:, 0]\n",
    "y_pred_orig_2022Q3 = scaler.inverse_transform(y_pred_orig_2022Q3)[:, 0]\n",
    "y_pred_orig_2022Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1362,
   "id": "3419424f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 541ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([896253.75938416, 897477.40659118, 897634.45240259])"
      ]
     },
     "execution_count": 1362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict Q4 of 2022 ST no X\n",
    "start_date = '2022-10-01'\n",
    "end_date = '2022-12-01'\n",
    "dates = pd.date_range(start_date, end_date, freq='MS')\n",
    "X = []\n",
    "for date in dates:\n",
    "    past_data = df2.loc[date - pd.DateOffset(months=window_size):date - pd.DateOffset(months=1)]\n",
    "    past_data = scaler.transform(past_data)\n",
    "    X.append(past_data)\n",
    "X = np.array(X)\n",
    "y_pred_2022Q4 = model.predict(X)\n",
    "y_pred_orig_2022Q4 = np.zeros((len(y_pred_2022Q4), df2.shape[1]))\n",
    "y_pred_orig_2022Q4[:, 0] = y_pred_2022Q4[:, 0]\n",
    "y_pred_orig_2022Q4 = scaler.inverse_transform(y_pred_orig_2022Q4)[:, 0]\n",
    "y_pred_orig_2022Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1084,
   "id": "89dd07ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([873615.28995633, 888939.02403116, 898252.77596712, 902030.31694889,\n",
       "       907128.14351916, 913319.14535165, 921832.84494281, 932296.33024335,\n",
       "       942782.97904134, 945645.49434185, 946484.10749435, 949050.22457242])"
      ]
     },
     "execution_count": 1084,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_orig_2022 = np.zeros((len(y_pred_2022), df2.shape[1]))\n",
    "y_pred_orig_2022[:, 0] = y_pred_2022[:, 0]\n",
    "y_pred_orig_2022 = scaler.inverse_transform(y_pred_orig_2022)[:, 0]\n",
    "y_pred_orig_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1171,
   "id": "70ee69aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 508ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([802735.73061824, 800823.93169403, 800090.22960067])"
      ]
     },
     "execution_count": 1171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict Q1 2021 no X \n",
    "start_date = '2021-01-01'\n",
    "end_date = '2021-03-01'\n",
    "dates = pd.date_range(start_date, end_date, freq='MS')\n",
    "X = []\n",
    "for date in dates:\n",
    "    past_data = df2.loc[date - pd.DateOffset(months=window_size):date - pd.DateOffset(months=1)]\n",
    "    past_data = scaler.transform(past_data)\n",
    "    X.append(past_data)\n",
    "X = np.array(X)\n",
    "y_pred_2021Q1 = model.predict(X)\n",
    "y_pred_orig_2021Q1 = np.zeros((len(y_pred_2021Q1), df2.shape[1]))\n",
    "y_pred_orig_2021Q1[:, 0] = y_pred_2021Q1[:, 0]\n",
    "y_pred_orig_2021Q1 = scaler.inverse_transform(y_pred_orig_2021Q1)[:, 0]\n",
    "y_pred_orig_2021Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1214,
   "id": "b7590dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 512ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([794011.09462976, 796840.28285742, 801145.82327008])"
      ]
     },
     "execution_count": 1214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict Q2 2021 no X \n",
    "start_date = '2021-04-01'\n",
    "end_date = '2021-06-01'\n",
    "dates = pd.date_range(start_date, end_date, freq='MS')\n",
    "X = []\n",
    "for date in dates:\n",
    "    past_data = df2.loc[date - pd.DateOffset(months=window_size):date - pd.DateOffset(months=1)]\n",
    "    past_data = scaler.transform(past_data)\n",
    "    X.append(past_data)\n",
    "X = np.array(X)\n",
    "y_pred_2021Q2 = model.predict(X)\n",
    "y_pred_orig_2021Q2 = np.zeros((len(y_pred_2021Q2), df2.shape[1]))\n",
    "y_pred_orig_2021Q2[:, 0] = y_pred_2021Q2[:, 0]\n",
    "y_pred_orig_2021Q2 = scaler.inverse_transform(y_pred_orig_2021Q2)[:, 0]\n",
    "y_pred_orig_2021Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1255,
   "id": "5502e4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 530ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([818287.4867022 , 822245.97984552, 825396.58692479])"
      ]
     },
     "execution_count": 1255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict Q3 2021 no X \n",
    "start_date = '2021-07-01'\n",
    "end_date = '2021-09-01'\n",
    "dates = pd.date_range(start_date, end_date, freq='MS')\n",
    "X = []\n",
    "for date in dates:\n",
    "    past_data = df2.loc[date - pd.DateOffset(months=window_size):date - pd.DateOffset(months=1)]\n",
    "    past_data = scaler.transform(past_data)\n",
    "    X.append(past_data)\n",
    "X = np.array(X)\n",
    "y_pred_2021Q3 = model.predict(X)\n",
    "y_pred_orig_2021Q3 = np.zeros((len(y_pred_2021Q3), df2.shape[1]))\n",
    "y_pred_orig_2021Q3[:, 0] = y_pred_2021Q3[:, 0]\n",
    "y_pred_orig_2021Q3 = scaler.inverse_transform(y_pred_orig_2021Q3)[:, 0]\n",
    "y_pred_orig_2021Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1265,
   "id": "a23a73f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 500ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([853732.36504197, 858567.42435694, 863218.49256754])"
      ]
     },
     "execution_count": 1265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict Q4 2021 no X \n",
    "start_date = '2021-10-01'\n",
    "end_date = '2021-12-01'\n",
    "dates = pd.date_range(start_date, end_date, freq='MS')\n",
    "X = []\n",
    "for date in dates:\n",
    "    past_data = df2.loc[date - pd.DateOffset(months=window_size):date - pd.DateOffset(months=1)]\n",
    "    past_data = scaler.transform(past_data)\n",
    "    X.append(past_data)\n",
    "X = np.array(X)\n",
    "y_pred_2021Q4 = model.predict(X)\n",
    "y_pred_orig_2021Q4 = np.zeros((len(y_pred_2021Q4), df2.shape[1]))\n",
    "y_pred_orig_2021Q4[:, 0] = y_pred_2021Q4[:, 0]\n",
    "y_pred_orig_2021Q4 = scaler.inverse_transform(y_pred_orig_2021Q4)[:, 0]\n",
    "y_pred_orig_2021Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1074,
   "id": "382bfcfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 508ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict the entire year of 2021\n",
    "start_date = '2021-01-01'\n",
    "end_date = '2021-12-01'\n",
    "dates = pd.date_range(start_date, end_date, freq='MS')\n",
    "X = []\n",
    "for date in dates:\n",
    "    past_data = df2.loc[date - pd.DateOffset(months=window_size):date - pd.DateOffset(months=1)]\n",
    "    past_data = scaler.transform(past_data)\n",
    "    X.append(past_data)\n",
    "X = np.array(X)\n",
    "y_pred_2021 = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1075,
   "id": "82087703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([828659.80371833, 827903.98487449, 823268.21267605, 821673.2404232 ,\n",
       "       826661.66505218, 831931.32695556, 836344.47970986, 840284.80672836,\n",
       "       842149.80593324, 843991.50657654, 847802.17203498, 853999.92707372])"
      ]
     },
     "execution_count": 1075,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_orig_2021 = np.zeros((len(y_pred_2021), df2.shape[1]))\n",
    "y_pred_orig_2021[:, 0] = y_pred_2021[:, 0]\n",
    "y_pred_orig_2021 = scaler.inverse_transform(y_pred_orig_2021)[:, 0]\n",
    "y_pred_orig_2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1042,
   "id": "82fd4d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict the entire year of 2020\n",
    "start_date = '2020-01-01'\n",
    "end_date = '2020-12-01'\n",
    "dates = pd.date_range(start_date, end_date, freq='MS')\n",
    "X = []\n",
    "for date in dates:\n",
    "    past_data = df2.loc[date - pd.DateOffset(months=window_size):date - pd.DateOffset(months=1)]\n",
    "    past_data = scaler.transform(past_data)\n",
    "    X.append(past_data)\n",
    "X = np.array(X)\n",
    "y_pred_2020 = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1043,
   "id": "f9169449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([746110.97410321, 753312.93091178, 759978.78444195, 767679.0265739 ,\n",
       "       771673.07534814, 774285.99214554, 779606.91088438, 788434.7358644 ,\n",
       "       799208.09203386, 807053.56186628, 814519.83916759, 821717.74405241])"
      ]
     },
     "execution_count": 1043,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_orig_2020 = np.zeros((len(y_pred_2020), df2.shape[1]))\n",
    "y_pred_orig_2020[:, 0] = y_pred_2020[:, 0]\n",
    "y_pred_orig_2020 = scaler.inverse_transform(y_pred_orig_2020)[:, 0]\n",
    "y_pred_orig_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44aa5dda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9339bdae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03db34a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "mape_value = mape(y_test, y_pred)\n",
    "\n",
    "rmse_value = np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b301bd59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f08fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b927d84",
   "metadata": {},
   "source": [
    "## OPTIMAL NEURONS TEST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "27ecfecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 2s 16ms/step - loss: 0.2624\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2257\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1935\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1663\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1422\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1216\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1020\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0848\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0697\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0563\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0454\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0368\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0309\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0263\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0252\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0251\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0251\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0249\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0237\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0222\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0206\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0193\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0184\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0176\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0167\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0157\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0148\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0136\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0128\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0117\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0109\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0102\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0094\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0087\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0082\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0077\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0072\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0069\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0066\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0064\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0063\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0061\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0060\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0060\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0059\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0059\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0058\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0058\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0058\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0058\n",
      "1/1 [==============================] - 1s 516ms/step\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 2s 15ms/step - loss: 0.2772\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1782\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.1048\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0589\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0355\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0356\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0411\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0413\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0357\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0300\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0269\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0259\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0254\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0248\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0234\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0216\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0197\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0185\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0173\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0162\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0150\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0135\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0122\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0111\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0100\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0089\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0080\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0071\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0066\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0059\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0056\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0054\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0053\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0052\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0052\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0052\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0052\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0052\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0051\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0051\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0051\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0050\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0050\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0050\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0050\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0050\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0050\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0050\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0050\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0049\n",
      "1/1 [==============================] - 1s 513ms/step\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 2s 13ms/step - loss: 0.0904\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0444\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0396\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0400\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0296\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0210\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0190\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0165\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0114\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0084\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0080\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0066\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0065\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0069\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0064\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0064\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0060\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0056\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0056\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0055\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0055\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0054\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0055\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0054\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0053\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0053\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0052\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0053\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0053\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0052\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0051\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0051\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0051\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0051\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0051\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0050\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0050\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0050\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0050\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0050\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0049\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0050\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0049\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0050\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0049\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0049\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0049\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0049\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0050\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0049\n",
      "1/1 [==============================] - 1s 863ms/step\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 2s 15ms/step - loss: 0.1731\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0669\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0269\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0389\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0342\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0187\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0158\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0171\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0153\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0112\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0081\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0080\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0079\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0061\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0057\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0060\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0055\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0053\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0057\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0056\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0053\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0053\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0052\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0052\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0052\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0051\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0051\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0051\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0052\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0051\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0051\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0051\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0050\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0050\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0051\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0050\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0050\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0050\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0050\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0050\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0049\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0050\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0049\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0049\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0049\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0049\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0049\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0049\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0049\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0049\n",
      "1/1 [==============================] - 1s 506ms/step\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 2s 17ms/step - loss: 0.1900\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0729\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0305\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0400\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0293\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0159\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0165\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0163\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0112\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0077\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0082\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0071\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0054\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0062\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0061\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0057\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0059\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0055\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0053\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0054\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0051\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0052\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0052\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0052\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0051\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0051\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0051\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0051\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0051\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0051\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0050\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0050\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0051\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0050\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0051\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0050\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0050\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0050\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0050\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0050\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0049\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0050\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0049\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0049\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0049\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0049\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0049\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0049\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0049\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0049\n",
      "1/1 [==============================] - 1s 856ms/step\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 2s 15ms/step - loss: 0.2134\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0627\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0297\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0450\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0250\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0162\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0196\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0180\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0115\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0079\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0088\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0075\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0053\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0062\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0062\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0056\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0059\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0056\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0054\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0055\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0052\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0053\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0053\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0052\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0052\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0051\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0052\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0052\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0052\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0052\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0051\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0051\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0051\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0050\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0051\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0051\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0050\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0051\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0050\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0050\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0050\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0050\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0050\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0050\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0050\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0049\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0049\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0050\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0050\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0049\n",
      "1/1 [==============================] - 0s 464ms/step\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 2s 16ms/step - loss: 0.1082\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0271\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0393\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0153\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0171\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0169\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0081\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0078\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0082\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0058\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0069\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0059\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0057\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0058\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0053\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0054\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0052\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0051\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0053\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0052\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0051\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0050\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0050\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0050\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0050\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0050\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0050\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0050\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0051\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0051\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0050\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0050\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0050\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0049\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0050\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0049\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0049\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0049\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0049\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0049\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0048\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0048\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0048\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0048\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0048\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0048\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0048\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0048\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0048\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0047\n",
      "1/1 [==============================] - 1s 728ms/step\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 2s 16ms/step - loss: 0.1114\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0276\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0348\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0137\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0184\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0136\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0076\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0097\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0060\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0073\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0068\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0055\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0063\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0053\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0058\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0055\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0051\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0054\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0051\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0054\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0051\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0051\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0052\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0051\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0050\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0050\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0050\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0051\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0051\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0051\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0049\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0050\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0049\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0048\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0050\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0048\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0049\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0048\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0048\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0048\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0048\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0048\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0048\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0048\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0048\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0047\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0047\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0047\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0048\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0046\n",
      "1/1 [==============================] - 1s 513ms/step\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 2s 18ms/step - loss: 0.1357\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0399\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0488\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0236\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0252\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0210\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0112\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0107\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0080\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0070\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0077\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0060\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0068\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0057\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0059\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0055\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0052\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0054\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0052\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0055\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0052\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0052\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0052\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0052\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0051\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0051\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0050\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0051\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0052\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0052\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0050\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0050\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0050\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0049\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0050\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0049\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0049\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0049\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0049\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0049\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0048\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0049\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0048\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0048\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0048\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0047\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0047\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0048\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0049\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0047\n",
      "1/1 [==============================] - 1s 830ms/step\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 2s 16ms/step - loss: 0.1078\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0256\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0314\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0122\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0169\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0113\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0075\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0093\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0057\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0076\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0063\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0054\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0061\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0052\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0057\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0054\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0050\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0053\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0050\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0054\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0051\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0051\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0051\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0050\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0050\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0049\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0049\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0050\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0051\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0051\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0049\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0049\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0049\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0048\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0049\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0048\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0048\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0048\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0048\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0048\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0047\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0048\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0047\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0047\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0047\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0046\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0046\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0046\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0047\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0046\n",
      "1/1 [==============================] - 0s 452ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def build_and_train_model(neurons, X_train, y_train, epochs=50, batch_size=32):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neurons, return_sequences=True, input_shape=(window_size, X.shape[2])))\n",
    "    model.add(LSTM(neurons))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "    \n",
    "    return model\n",
    "\n",
    "neurons_list = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "rmse_values = []\n",
    "for neurons in neurons_list:\n",
    "    model = build_and_train_model(neurons, X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    y_pred_orig = np.zeros((len(y_pred), df.shape[1]))\n",
    "    y_pred_orig[:, 0] = y_pred[:, 0]\n",
    "    y_pred_orig = scaler.inverse_transform(y_pred_orig)[:, 0]\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    rmse_values.append(rmse)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(neurons_list, rmse_values)\n",
    "plt.xlabel('Number of neurons')\n",
    "plt.ylabel('RMSE')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b904999",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000d75b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25a6787",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd39c2d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944a83e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "adcb4148",
   "metadata": {},
   "source": [
    "# MULTI STEP LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8c6955",
   "metadata": {},
   "source": [
    "## multistep w EXO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1365,
   "id": "4cbbf889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Median Price</th>\n",
       "      <th>CPI_Can</th>\n",
       "      <th>Inflation</th>\n",
       "      <th>Bank_Rate</th>\n",
       "      <th>CAN_Mort_Lending_Rate5yr</th>\n",
       "      <th>Mortgage_Var_Rate</th>\n",
       "      <th>Mortgage_Fixed_Rate_5yr</th>\n",
       "      <th>Bond_1-3yr_Avg</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>413500</td>\n",
       "      <td>121.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.25</td>\n",
       "      <td>4.14</td>\n",
       "      <td>3.57</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-01</th>\n",
       "      <td>434000</td>\n",
       "      <td>122.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.25</td>\n",
       "      <td>4.11</td>\n",
       "      <td>3.52</td>\n",
       "      <td>2.98</td>\n",
       "      <td>1.12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-01</th>\n",
       "      <td>441000</td>\n",
       "      <td>122.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.25</td>\n",
       "      <td>4.02</td>\n",
       "      <td>3.51</td>\n",
       "      <td>2.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-01</th>\n",
       "      <td>453500</td>\n",
       "      <td>122.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.25</td>\n",
       "      <td>4.02</td>\n",
       "      <td>3.52</td>\n",
       "      <td>2.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-01</th>\n",
       "      <td>478500</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.25</td>\n",
       "      <td>4.02</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.96</td>\n",
       "      <td>1.04</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>797500</td>\n",
       "      <td>153.9</td>\n",
       "      <td>6.4</td>\n",
       "      <td>4.50</td>\n",
       "      <td>5.86</td>\n",
       "      <td>6.31</td>\n",
       "      <td>5.25</td>\n",
       "      <td>3.83</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-01</th>\n",
       "      <td>850000</td>\n",
       "      <td>154.5</td>\n",
       "      <td>6.2</td>\n",
       "      <td>4.75</td>\n",
       "      <td>5.81</td>\n",
       "      <td>6.35</td>\n",
       "      <td>5.14</td>\n",
       "      <td>4.09</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-01</th>\n",
       "      <td>850000</td>\n",
       "      <td>155.3</td>\n",
       "      <td>5.9</td>\n",
       "      <td>4.75</td>\n",
       "      <td>5.81</td>\n",
       "      <td>6.59</td>\n",
       "      <td>5.09</td>\n",
       "      <td>3.87</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-01</th>\n",
       "      <td>875000</td>\n",
       "      <td>156.4</td>\n",
       "      <td>5.7</td>\n",
       "      <td>4.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>6.65</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.73</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-01</th>\n",
       "      <td>928800</td>\n",
       "      <td>157.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>4.75</td>\n",
       "      <td>5.74</td>\n",
       "      <td>6.81</td>\n",
       "      <td>4.95</td>\n",
       "      <td>3.95</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Median Price  CPI_Can  Inflation  Bank_Rate  \\\n",
       "Month                                                     \n",
       "2013-01-01        413500    121.3        1.3       1.25   \n",
       "2013-02-01        434000    122.7        1.5       1.25   \n",
       "2013-03-01        441000    122.9        1.5       1.25   \n",
       "2013-04-01        453500    122.7        1.2       1.25   \n",
       "2013-05-01        478500    123.0        1.2       1.25   \n",
       "...                  ...      ...        ...        ...   \n",
       "2023-01-01        797500    153.9        6.4       4.50   \n",
       "2023-02-01        850000    154.5        6.2       4.75   \n",
       "2023-03-01        850000    155.3        5.9       4.75   \n",
       "2023-04-01        875000    156.4        5.7       4.75   \n",
       "2023-05-01        928800    157.0        5.2       4.75   \n",
       "\n",
       "            CAN_Mort_Lending_Rate5yr  Mortgage_Var_Rate  \\\n",
       "Month                                                     \n",
       "2013-01-01                      4.14               3.57   \n",
       "2013-02-01                      4.11               3.52   \n",
       "2013-03-01                      4.02               3.51   \n",
       "2013-04-01                      4.02               3.52   \n",
       "2013-05-01                      4.02               3.50   \n",
       "...                              ...                ...   \n",
       "2023-01-01                      5.86               6.31   \n",
       "2023-02-01                      5.81               6.35   \n",
       "2023-03-01                      5.81               6.59   \n",
       "2023-04-01                      5.75               6.65   \n",
       "2023-05-01                      5.74               6.81   \n",
       "\n",
       "            Mortgage_Fixed_Rate_5yr  Bond_1-3yr_Avg  month  \n",
       "Month                                                       \n",
       "2013-01-01                     3.00            1.16      1  \n",
       "2013-02-01                     2.98            1.12      2  \n",
       "2013-03-01                     2.99            1.01      3  \n",
       "2013-04-01                     2.99            1.00      4  \n",
       "2013-05-01                     2.96            1.04      5  \n",
       "...                             ...             ...    ...  \n",
       "2023-01-01                     5.25            3.83      1  \n",
       "2023-02-01                     5.14            4.09      2  \n",
       "2023-03-01                     5.09            3.87      3  \n",
       "2023-04-01                     5.00            3.73      4  \n",
       "2023-05-01                     4.95            3.95      5  \n",
       "\n",
       "[125 rows x 9 columns]"
      ]
     },
     "execution_count": 1365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "df = pd.read_csv('lstm_data.csv', index_col='Month', parse_dates=True)\n",
    "df['month'] = df.index.month\n",
    "df = df[['Median Price', 'CPI_Can', 'Inflation', 'Bank_Rate', 'CAN_Mort_Lending_Rate5yr', 'Mortgage_Var_Rate', 'Mortgage_Fixed_Rate_5yr', 'Bond_1-3yr_Avg', 'month']]   \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1243,
   "id": "3625d486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 2s 47ms/step - loss: 0.3504\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.3152\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.2858\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.2587\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2293\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1975\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1638\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1334\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1126\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0956\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0785\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0616\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0489\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0415\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0355\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0296\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0249\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0223\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0195\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0169\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0155\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0144\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0130\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0123\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0115\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0110\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0105\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0101\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0098\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0093\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0089\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0085\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0083\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0081\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0079\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0078\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0076\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0074\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0072\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0070\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0069\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0068\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0067\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0066\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0065\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0064\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0063\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0063\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0062\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0062\n",
      "1/1 [==============================] - 1s 549ms/step\n",
      "1/1 [==============================] - 1s 533ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "\n",
    "window_size = 48\n",
    "horizons = [12]\n",
    "\n",
    "X, Ys = [], [[] for _ in horizons]\n",
    "for i in range(window_size, len(scaled_data) - max(horizons)):\n",
    "    X.append(scaled_data[i-window_size:i])\n",
    "    for j, horizon in enumerate(horizons):\n",
    "        Ys[j].append(scaled_data[i:i+horizon, 0])\n",
    "X = np.array(X)\n",
    "Ys = [np.array(Y) for Y in Ys]\n",
    "\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "Y_trains, Y_tests = [], []\n",
    "for Y in Ys:\n",
    "    Y_train, Y_test = Y[:split], Y[split:]\n",
    "    Y_trains.append(Y_train)\n",
    "    Y_tests.append(Y_test)\n",
    "\n",
    "models = []\n",
    "for horizon, Y_train in zip(horizons, Y_trains):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(30, return_sequences=True, input_shape=(window_size, X.shape[2])))\n",
    "    model.add(LSTM(30))\n",
    "    model.add(Dense(horizon))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(X_train, Y_train, epochs=50, batch_size=32)\n",
    "    models.append(model)\n",
    "\n",
    "for horizon, model in zip(horizons, models):\n",
    "    model.save(f'lstm_model_{horizon}.h5')\n",
    "\n",
    "Y_preds = []\n",
    "for model in models:\n",
    "    Y_pred = model.predict(X_test)\n",
    "    Y_preds.append(Y_pred)\n",
    "\n",
    "time_periods = [ # last 4 months of 2022\n",
    "    ('2020-01-01', '2020-12-01') # last 12 months of 2022\n",
    "]\n",
    "input_seqs = []\n",
    "for start_date, end_date in time_periods:\n",
    "    start_idx = df.index.get_loc(start_date) - window_size\n",
    "    end_idx = df.index.get_loc(end_date)\n",
    "    if start_idx < 0:\n",
    "        print(f'Not enough data for date range {start_date} to {end_date}')\n",
    "        continue\n",
    "    input_seq = scaled_data[start_idx:end_idx][-window_size:]\n",
    "    input_seq = input_seq.reshape((1, window_size, -1))\n",
    "    input_seqs.append(input_seq)\n",
    "\n",
    "\n",
    "models = []\n",
    "for horizon in horizons:\n",
    "    model = load_model(f'lstm_model_{horizon}.h5')\n",
    "    models.append(model)\n",
    "\n",
    "Y_preds = []\n",
    "for input_seq in input_seqs:\n",
    "    y_preds = []\n",
    "    for model in models:\n",
    "        y_pred = model.predict(input_seq)\n",
    "        y_preds.append(y_pred)\n",
    "    Y_preds.append(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1013,
   "id": "745a3b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([[0.6596868 , 0.6364569 , 0.62981   , 0.70192254, 0.67709357,\n",
       "          0.64061785, 0.66132414, 0.6878917 , 0.684299  , 0.7262048 ,\n",
       "          0.6658412 , 0.7178532 ]], dtype=float32)]]"
      ]
     },
     "execution_count": 1013,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1014,
   "id": "d024816a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([787212.57436275, 774052.83769965, 770287.35119104, 811139.11658525,\n",
       "       797073.50483537, 776410.01057625, 788140.12724161, 803190.66035748,\n",
       "       801155.37905693, 824895.02629638, 790699.05215502, 820163.83129358])"
      ]
     },
     "execution_count": 1014,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_2020_ms_RS = Y_preds[0][0].reshape((-1, 1))\n",
    "y_pred_orig_2020_ms = np.zeros((len(y_pred_2020_ms_RS), df.shape[1]))\n",
    "y_pred_orig_2020_ms[:, 0] = y_pred_2020_ms_RS[:, 0]\n",
    "y_pred_orig_2020_ms = scaler.inverse_transform(y_pred_orig_2020_ms)[:, 0]\n",
    "y_pred_orig_2020_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1069,
   "id": "1201ab96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 2s 47ms/step - loss: 0.2850\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.2504\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.2159\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1834\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1529\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1277\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1072\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0890\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0720\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0560\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0444\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0366\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0308\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0259\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0229\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0206\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0180\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0160\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0151\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0146\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0143\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0140\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0132\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0127\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0120\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0116\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0111\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0108\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0104\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0101\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0098\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0095\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0092\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0090\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0088\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0086\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0084\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0082\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0080\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0078\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0077\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0075\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0073\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0072\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0071\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0069\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0068\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0067\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0066\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0065\n",
      "1/1 [==============================] - 1s 522ms/step\n",
      "1/1 [==============================] - 1s 528ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "\n",
    "window_size = 48\n",
    "horizons = [12]\n",
    "\n",
    "X, Ys = [], [[] for _ in horizons]\n",
    "for i in range(window_size, len(scaled_data) - max(horizons)):\n",
    "    X.append(scaled_data[i-window_size:i])\n",
    "    for j, horizon in enumerate(horizons):\n",
    "        Ys[j].append(scaled_data[i:i+horizon, 0])\n",
    "X = np.array(X)\n",
    "Ys = [np.array(Y) for Y in Ys]\n",
    "\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "Y_trains, Y_tests = [], []\n",
    "for Y in Ys:\n",
    "    Y_train, Y_test = Y[:split], Y[split:]\n",
    "    Y_trains.append(Y_train)\n",
    "    Y_tests.append(Y_test)\n",
    "\n",
    "models = []\n",
    "for horizon, Y_train in zip(horizons, Y_trains):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(30, return_sequences=True, input_shape=(window_size, X.shape[2])))\n",
    "    model.add(LSTM(30))\n",
    "    model.add(Dense(horizon))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(X_train, Y_train, epochs=50, batch_size=32)\n",
    "    models.append(model)\n",
    "\n",
    "for horizon, model in zip(horizons, models):\n",
    "    model.save(f'lstm_model_{horizon}.h5')\n",
    "\n",
    "Y_preds = []\n",
    "for model in models:\n",
    "    Y_pred = model.predict(X_test)\n",
    "    Y_preds.append(Y_pred)\n",
    "\n",
    "time_periods = [ # last 4 months of 2022\n",
    "    ('2021-01-01', '2021-12-01') # last 12 months of 2022\n",
    "]\n",
    "input_seqs = []\n",
    "for start_date, end_date in time_periods:\n",
    "    start_idx = df.index.get_loc(start_date) - window_size\n",
    "    end_idx = df.index.get_loc(end_date)\n",
    "    if start_idx < 0:\n",
    "        print(f'Not enough data for date range {start_date} to {end_date}')\n",
    "        continue\n",
    "    input_seq = scaled_data[start_idx:end_idx][-window_size:]\n",
    "    input_seq = input_seq.reshape((1, window_size, -1))\n",
    "    input_seqs.append(input_seq)\n",
    "\n",
    "\n",
    "models = []\n",
    "for horizon in horizons:\n",
    "    model = load_model(f'lstm_model_{horizon}.h5')\n",
    "    models.append(model)\n",
    "\n",
    "Y_preds = []\n",
    "for input_seq in input_seqs:\n",
    "    y_preds = []\n",
    "    for model in models:\n",
    "        y_pred = model.predict(input_seq)\n",
    "        y_preds.append(y_pred)\n",
    "    Y_preds.append(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1070,
   "id": "a6051756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([[0.62253517, 0.68294984, 0.6838406 , 0.7141911 , 0.64804506,\n",
       "          0.7245905 , 0.68127936, 0.5871307 , 0.7021383 , 0.72991395,\n",
       "          0.7368447 , 0.7141205 ]], dtype=float32)]]"
      ]
     },
     "execution_count": 1070,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1071,
   "id": "ca5a0dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([766166.17330909, 800391.08493924, 800895.68451047, 818089.24633265,\n",
       "       780617.52820015, 823980.50710559, 799444.758147  , 746109.5559299 ,\n",
       "       811261.34961843, 826996.25265598, 830922.53300548, 818049.26735163])"
      ]
     },
     "execution_count": 1071,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_2021_ms_RS = Y_preds[0][0].reshape((-1, 1))\n",
    "y_pred_orig_2021_ms = np.zeros((len(y_pred_2021_ms_RS), df.shape[1]))\n",
    "y_pred_orig_2021_ms[:, 0] = y_pred_2021_ms_RS[:, 0]\n",
    "y_pred_orig_2021_ms = scaler.inverse_transform(y_pred_orig_2021_ms)[:, 0]\n",
    "y_pred_orig_2021_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1308,
   "id": "51a76a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 2s 23ms/step - loss: 0.2176\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1091\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0419\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0311\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0362\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0233\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0218\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0236\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0207\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0164\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0141\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0135\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0115\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0089\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0077\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0070\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0065\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0061\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0059\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0055\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0054\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0054\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0053\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0052\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0051\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0052\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0051\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0051\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0050\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0049\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0049\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0048\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0049\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0049\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0048\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0048\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0048\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0047\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0048\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0048\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0047\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0048\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0047\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0047\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0046\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0047\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0046\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0047\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0047\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0046\n",
      "1/1 [==============================] - 1s 566ms/step\n",
      "1/1 [==============================] - 1s 539ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    }
   ],
   "source": [
    "# 2021 Qaurters \n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "\n",
    "window_size = 24\n",
    "horizons = [3]\n",
    "\n",
    "X, Ys = [], [[] for _ in horizons]\n",
    "for i in range(window_size, len(scaled_data) - max(horizons)):\n",
    "    X.append(scaled_data[i-window_size:i])\n",
    "    for j, horizon in enumerate(horizons):\n",
    "        Ys[j].append(scaled_data[i:i+horizon, 0])\n",
    "X = np.array(X)\n",
    "Ys = [np.array(Y) for Y in Ys]\n",
    "\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "Y_trains, Y_tests = [], []\n",
    "for Y in Ys:\n",
    "    Y_train, Y_test = Y[:split], Y[split:]\n",
    "    Y_trains.append(Y_train)\n",
    "    Y_tests.append(Y_test)\n",
    "\n",
    "models = []\n",
    "for horizon, Y_train in zip(horizons, Y_trains):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(40, return_sequences=True, input_shape=(window_size, X.shape[2])))\n",
    "    model.add(LSTM(40))\n",
    "    model.add(Dense(horizon))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(X_train, Y_train, epochs=50, batch_size=32)\n",
    "    models.append(model)\n",
    "\n",
    "for horizon, model in zip(horizons, models):\n",
    "    model.save(f'lstm_model_{horizon}.h5')\n",
    "\n",
    "Y_preds = []\n",
    "for model in models:\n",
    "    Y_pred = model.predict(X_test)\n",
    "    Y_preds.append(Y_pred)\n",
    "\n",
    "time_periods = [ \n",
    "    ('2021-01-01', '2021-03-01'), \n",
    "    ('2021-04-01', '2021-06-01'), \n",
    "    ('2021-07-01', '2021-09-01'), \n",
    "    ('2021-10-01', '2021-12-01')\n",
    "]\n",
    "input_seqs = []\n",
    "for start_date, end_date in time_periods:\n",
    "    start_idx = df.index.get_loc(start_date) - window_size\n",
    "    end_idx = df.index.get_loc(end_date)\n",
    "    if start_idx < 0:\n",
    "        print(f'Not enough data for date range {start_date} to {end_date}')\n",
    "        continue\n",
    "    input_seq = scaled_data[start_idx:end_idx][-window_size:]\n",
    "    input_seq = input_seq.reshape((1, window_size, -1))\n",
    "    input_seqs.append(input_seq)\n",
    "\n",
    "\n",
    "models = []\n",
    "for horizon in horizons:\n",
    "    model = load_model(f'lstm_model_{horizon}.h5')\n",
    "    models.append(model)\n",
    "\n",
    "Y_preds = []\n",
    "for input_seq in input_seqs:\n",
    "    y_preds = []\n",
    "    for model in models:\n",
    "        y_pred = model.predict(input_seq)\n",
    "        y_preds.append(y_pred)\n",
    "    Y_preds.append(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1193,
   "id": "87716376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([[0.6842928 , 0.71018773, 0.7098075 ]], dtype=float32)],\n",
       " [array([[0.7125576 , 0.7456454 , 0.74524343]], dtype=float32)],\n",
       " [array([[0.74369913, 0.78211164, 0.78614366]], dtype=float32)],\n",
       " [array([[0.7761427 , 0.81131953, 0.8277308 ]], dtype=float32)]]"
      ]
     },
     "execution_count": 1193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1194,
   "id": "0bee7651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([801151.86738968, 815821.35084271, 815605.95732927])"
      ]
     },
     "execution_count": 1194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q1\n",
    "y_pred_2021Q1_ms_RS = Y_preds[0][0].reshape((-1, 1))\n",
    "y_pred_orig_2021Q1_ms = np.zeros((len(y_pred_2021Q1_ms_RS), df.shape[1]))\n",
    "y_pred_orig_2021Q1_ms[:, 0] = y_pred_2021Q1_ms_RS[:, 0]\n",
    "y_pred_orig_2021Q1_ms = scaler.inverse_transform(y_pred_orig_2021Q1_ms)[:, 0]\n",
    "y_pred_orig_2021Q1_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1227,
   "id": "91a196e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([840695.19907236, 832310.9922111 , 833721.93959355])"
      ]
     },
     "execution_count": 1227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q2\n",
    "y_pred_2021Q2_ms_RS = Y_preds[1][0].reshape((-1, 1))\n",
    "y_pred_orig_2021Q2_ms = np.zeros((len(y_pred_2021Q2_ms_RS), df.shape[1]))\n",
    "y_pred_orig_2021Q2_ms[:, 0] = y_pred_2021Q2_ms_RS[:, 0]\n",
    "y_pred_orig_2021Q2_ms = scaler.inverse_transform(y_pred_orig_2021Q2_ms)[:, 0]\n",
    "y_pred_orig_2021Q2_ms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1245,
   "id": "b8b38498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([827074.28595424, 824268.05862784, 829302.30376124])"
      ]
     },
     "execution_count": 1245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q3\n",
    "y_pred_2021Q3_ms_RS = Y_preds[2][0].reshape((-1, 1))\n",
    "y_pred_orig_2021Q3_ms = np.zeros((len(y_pred_2021Q3_ms_RS), df.shape[1]))\n",
    "y_pred_orig_2021Q3_ms[:, 0] = y_pred_2021Q3_ms_RS[:, 0]\n",
    "y_pred_orig_2021Q3_ms = scaler.inverse_transform(y_pred_orig_2021Q3_ms)[:, 0]\n",
    "y_pred_orig_2021Q3_ms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1309,
   "id": "68cbd1e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([865687.09334731, 836066.8554008 , 853635.49029827])"
      ]
     },
     "execution_count": 1309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q4\n",
    "y_pred_2021Q4_ms_RS = Y_preds[3][0].reshape((-1, 1))\n",
    "y_pred_orig_2021Q4_ms = np.zeros((len(y_pred_2021Q4_ms_RS), df.shape[1]))\n",
    "y_pred_orig_2021Q4_ms[:, 0] = y_pred_2021Q4_ms_RS[:, 0]\n",
    "y_pred_orig_2021Q4_ms = scaler.inverse_transform(y_pred_orig_2021Q4_ms)[:, 0]\n",
    "y_pred_orig_2021Q4_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1109,
   "id": "b7e0cdc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 2s 49ms/step - loss: 0.4018\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.3525\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.3060\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.2606\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2123\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1616\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1104\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0700\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0487\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0473\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0436\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0350\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0259\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0211\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0206\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0202\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0192\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0179\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0170\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0167\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0153\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0146\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0144\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0143\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0141\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0136\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0130\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0126\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0122\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0120\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0117\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0115\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0114\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0113\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0109\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0105\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0102\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0098\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0094\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0091\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0089\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0085\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0082\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0081\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0078\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0075\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0074\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0072\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0072\n",
      "1/1 [==============================] - 1s 564ms/step\n",
      "1/1 [==============================] - 1s 517ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "\n",
    "window_size = 60\n",
    "horizons = [12]\n",
    "\n",
    "X, Ys = [], [[] for _ in horizons]\n",
    "for i in range(window_size, len(scaled_data) - max(horizons)):\n",
    "    X.append(scaled_data[i-window_size:i])\n",
    "    for j, horizon in enumerate(horizons):\n",
    "        Ys[j].append(scaled_data[i:i+horizon, 0])\n",
    "X = np.array(X)\n",
    "Ys = [np.array(Y) for Y in Ys]\n",
    "\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "Y_trains, Y_tests = [], []\n",
    "for Y in Ys:\n",
    "    Y_train, Y_test = Y[:split], Y[split:]\n",
    "    Y_trains.append(Y_train)\n",
    "    Y_tests.append(Y_test)\n",
    "\n",
    "models = []\n",
    "for horizon, Y_train in zip(horizons, Y_trains):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(30, return_sequences=True, input_shape=(window_size, X.shape[2])))\n",
    "    model.add(LSTM(30))\n",
    "    model.add(Dense(horizon))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(X_train, Y_train, epochs=50, batch_size=32)\n",
    "    models.append(model)\n",
    "\n",
    "for horizon, model in zip(horizons, models):\n",
    "    model.save(f'lstm_model_{horizon}.h5')\n",
    "\n",
    "Y_preds = []\n",
    "for model in models:\n",
    "    Y_pred = model.predict(X_test)\n",
    "    Y_preds.append(Y_pred)\n",
    "\n",
    "time_periods = [ # last 4 months of 2022\n",
    "    ('2022-01-01', '2022-12-01') # last 12 months of 2022\n",
    "]\n",
    "input_seqs = []\n",
    "for start_date, end_date in time_periods:\n",
    "    start_idx = df.index.get_loc(start_date) - window_size\n",
    "    end_idx = df.index.get_loc(end_date)\n",
    "    if start_idx < 0:\n",
    "        print(f'Not enough data for date range {start_date} to {end_date}')\n",
    "        continue\n",
    "    input_seq = scaled_data[start_idx:end_idx][-window_size:]\n",
    "    input_seq = input_seq.reshape((1, window_size, -1))\n",
    "    input_seqs.append(input_seq)\n",
    "\n",
    "\n",
    "models = []\n",
    "for horizon in horizons:\n",
    "    model = load_model(f'lstm_model_{horizon}.h5')\n",
    "    models.append(model)\n",
    "\n",
    "Y_preds = []\n",
    "for input_seq in input_seqs:\n",
    "    y_preds = []\n",
    "    for model in models:\n",
    "        y_pred = model.predict(input_seq)\n",
    "        y_preds.append(y_pred)\n",
    "    Y_preds.append(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1110,
   "id": "cb61b6c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([[0.65953004, 0.8506704 , 0.79740804, 0.80622727, 0.7246147 ,\n",
       "          0.79482114, 0.7531331 , 0.8548297 , 0.72657853, 0.8607659 ,\n",
       "          0.8474275 , 0.85837704]], dtype=float32)]]"
      ]
     },
     "execution_count": 1110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1111,
   "id": "98278603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([787123.76970053, 895404.78006005, 865231.65711761, 870227.74663568,\n",
       "       823994.21611428, 863766.17759466, 840149.91143346, 897761.04125381,\n",
       "       825106.73931241, 901123.86783957, 893567.671597  , 899770.59283853])"
      ]
     },
     "execution_count": 1111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_2022_ms_RS = Y_preds[0][0].reshape((-1, 1))\n",
    "y_pred_orig_2022_ms = np.zeros((len(y_pred_2022_ms_RS), df.shape[1]))\n",
    "y_pred_orig_2022_ms[:, 0] = y_pred_2022_ms_RS[:, 0]\n",
    "y_pred_orig_2022_ms = scaler.inverse_transform(y_pred_orig_2022_ms)[:, 0]\n",
    "y_pred_orig_2022_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1366,
   "id": "87c57828",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 2s 51ms/step - loss: 0.2931\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1691\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0863\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0519\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0557\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0429\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0271\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0238\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0276\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0277\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0239\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0196\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0175\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0168\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0144\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0118\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0111\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0113\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0110\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0098\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0085\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0085\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0085\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0078\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0072\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0072\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0074\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0072\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0069\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0069\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0068\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0066\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0065\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0065\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0063\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0063\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0062\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0061\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0061\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0061\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0060\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0061\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0059\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0058\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0059\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0058\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0058\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0058\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0057\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0057\n",
      "1/1 [==============================] - 1s 545ms/step\n",
      "1/1 [==============================] - 1s 545ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    }
   ],
   "source": [
    "# 2022 Qaurters \n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "\n",
    "window_size = 60\n",
    "horizons = [3]\n",
    "\n",
    "X, Ys = [], [[] for _ in horizons]\n",
    "for i in range(window_size, len(scaled_data) - max(horizons)):\n",
    "    X.append(scaled_data[i-window_size:i])\n",
    "    for j, horizon in enumerate(horizons):\n",
    "        Ys[j].append(scaled_data[i:i+horizon, 0])\n",
    "X = np.array(X)\n",
    "Ys = [np.array(Y) for Y in Ys]\n",
    "\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "Y_trains, Y_tests = [], []\n",
    "for Y in Ys:\n",
    "    Y_train, Y_test = Y[:split], Y[split:]\n",
    "    Y_trains.append(Y_train)\n",
    "    Y_tests.append(Y_test)\n",
    "\n",
    "models = []\n",
    "for horizon, Y_train in zip(horizons, Y_trains):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(40, return_sequences=True, input_shape=(window_size, X.shape[2])))\n",
    "    model.add(LSTM(40))\n",
    "    model.add(Dense(horizon))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(X_train, Y_train, epochs=50, batch_size=32)\n",
    "    models.append(model)\n",
    "\n",
    "for horizon, model in zip(horizons, models):\n",
    "    model.save(f'lstm_model_{horizon}.h5')\n",
    "\n",
    "Y_preds = []\n",
    "for model in models:\n",
    "    Y_pred = model.predict(X_test)\n",
    "    Y_preds.append(Y_pred)\n",
    "\n",
    "time_periods = [ \n",
    "    ('2022-01-01', '2022-03-01'), \n",
    "    ('2022-04-01', '2022-06-01'), \n",
    "    ('2022-07-01', '2022-09-01'), \n",
    "    ('2022-10-01', '2022-12-01')\n",
    "]\n",
    "input_seqs = []\n",
    "for start_date, end_date in time_periods:\n",
    "    start_idx = df.index.get_loc(start_date) - window_size\n",
    "    end_idx = df.index.get_loc(end_date)\n",
    "    if start_idx < 0:\n",
    "        print(f'Not enough data for date range {start_date} to {end_date}')\n",
    "        continue\n",
    "    input_seq = scaled_data[start_idx:end_idx][-window_size:]\n",
    "    input_seq = input_seq.reshape((1, window_size, -1))\n",
    "    input_seqs.append(input_seq)\n",
    "\n",
    "\n",
    "models = []\n",
    "for horizon in horizons:\n",
    "    model = load_model(f'lstm_model_{horizon}.h5')\n",
    "    models.append(model)\n",
    "\n",
    "Y_preds = []\n",
    "for input_seq in input_seqs:\n",
    "    y_preds = []\n",
    "    for model in models:\n",
    "        y_pred = model.predict(input_seq)\n",
    "        y_preds.append(y_pred)\n",
    "    Y_preds.append(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1331,
   "id": "e183c5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([884959.79854465, 900580.47109842, 916212.55657077])"
      ]
     },
     "execution_count": 1331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict Q1 2022 MS X \n",
    "start_date = '2022-01-01'\n",
    "end_date = '2022-03-01'\n",
    "dates = pd.date_range(start_date, end_date, freq='MS')\n",
    "X = []\n",
    "for date in dates:\n",
    "    past_data = df.loc[date - pd.DateOffset(months=window_size):date - pd.DateOffset(months=1)]\n",
    "    past_data = scaler.transform(past_data)\n",
    "    X.append(past_data)\n",
    "X = np.array(X)\n",
    "y_pred_2022Q1 = model.predict(X)\n",
    "y_pred_orig_2022Q1 = np.zeros((len(y_pred_2022Q1), df.shape[1]))\n",
    "y_pred_orig_2022Q1[:, 0] = y_pred_2022Q1[:, 0]\n",
    "y_pred_orig_2022Q1 = scaler.inverse_transform(y_pred_orig_2022Q1)[:, 0]\n",
    "y_pred_orig_2022Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1332,
   "id": "076ae878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([930562.71466613, 942442.21225381, 951406.75589442])"
      ]
     },
     "execution_count": 1332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict Q2 2022 MS X \n",
    "start_date = '2022-04-01'\n",
    "end_date = '2022-06-01'\n",
    "dates = pd.date_range(start_date, end_date, freq='MS')\n",
    "X = []\n",
    "for date in dates:\n",
    "    past_data = df.loc[date - pd.DateOffset(months=window_size):date - pd.DateOffset(months=1)]\n",
    "    past_data = scaler.transform(past_data)\n",
    "    X.append(past_data)\n",
    "X = np.array(X)\n",
    "y_pred_2022Q2 = model.predict(X)\n",
    "y_pred_orig_2022Q2 = np.zeros((len(y_pred_2022Q2), df.shape[1]))\n",
    "y_pred_orig_2022Q2[:, 0] = y_pred_2022Q2[:, 0]\n",
    "y_pred_orig_2022Q2 = scaler.inverse_transform(y_pred_orig_2022Q2)[:, 0]\n",
    "y_pred_orig_2022Q2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1347,
   "id": "6040b127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([867046.91895843, 865024.84017611, 861569.32583451])"
      ]
     },
     "execution_count": 1347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict Q3 2022 MS X \n",
    "start_date = '2022-07-01'\n",
    "end_date = '2022-09-01'\n",
    "dates = pd.date_range(start_date, end_date, freq='MS')\n",
    "X = []\n",
    "for date in dates:\n",
    "    past_data = df.loc[date - pd.DateOffset(months=window_size):date - pd.DateOffset(months=1)]\n",
    "    past_data = scaler.transform(past_data)\n",
    "    X.append(past_data)\n",
    "X = np.array(X)\n",
    "y_pred_2022Q3 = model.predict(X)\n",
    "y_pred_orig_2022Q3 = np.zeros((len(y_pred_2022Q3), df.shape[1]))\n",
    "y_pred_orig_2022Q3[:, 0] = y_pred_2022Q3[:, 0]\n",
    "y_pred_orig_2022Q3 = scaler.inverse_transform(y_pred_orig_2022Q3)[:, 0]\n",
    "y_pred_orig_2022Q3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1367,
   "id": "9db4009e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([874722.51188755, 874357.23096132, 873065.61273336])"
      ]
     },
     "execution_count": 1367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict Q4 2022 MS X \n",
    "start_date = '2022-10-01'\n",
    "end_date = '2022-12-01'\n",
    "dates = pd.date_range(start_date, end_date, freq='MS')\n",
    "X = []\n",
    "for date in dates:\n",
    "    past_data = df.loc[date - pd.DateOffset(months=window_size):date - pd.DateOffset(months=1)]\n",
    "    past_data = scaler.transform(past_data)\n",
    "    X.append(past_data)\n",
    "X = np.array(X)\n",
    "y_pred_2022Q4 = model.predict(X)\n",
    "y_pred_orig_2022Q4 = np.zeros((len(y_pred_2022Q4), df.shape[1]))\n",
    "y_pred_orig_2022Q4[:, 0] = y_pred_2022Q4[:, 0]\n",
    "y_pred_orig_2022Q4 = scaler.inverse_transform(y_pred_orig_2022Q4)[:, 0]\n",
    "y_pred_orig_2022Q4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae33efc",
   "metadata": {},
   "source": [
    "## Multi Step without Exo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1114,
   "id": "58acc5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 2s 46ms/step - loss: 0.3991\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3766\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.3547\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.3335\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.3110\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.2869\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.2602\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.2310\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1980\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1654\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1331\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1062\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0834\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0630\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0430\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0282\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0196\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0169\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0167\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0170\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0163\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0154\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0143\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0134\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0127\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0121\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0115\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0111\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0108\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0104\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0102\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0099\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0096\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0095\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0093\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0089\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0086\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0084\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0080\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0079\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0078\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0074\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0073\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0073\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0069\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0068\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0069\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0066\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0067\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0064\n",
      "1/1 [==============================] - 1s 523ms/step\n",
      "1/1 [==============================] - 1s 528ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "df = pd.read_csv('lstm_data.csv', index_col='Month', parse_dates=True)\n",
    "df = df[['Median Price']]   \n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "\n",
    "window_size = 60\n",
    "horizons = [12]\n",
    "\n",
    "X, Ys = [], [[] for _ in horizons]\n",
    "for i in range(window_size, len(scaled_data) - max(horizons)):\n",
    "    X.append(scaled_data[i-window_size:i, 0])\n",
    "    for j, horizon in enumerate(horizons):\n",
    "        Ys[j].append(scaled_data[i:i+horizon, 0])\n",
    "X = np.array(X)\n",
    "Ys = [np.array(Y) for Y in Ys]\n",
    "X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "Y_trains, Y_tests = [], []\n",
    "for Y in Ys:\n",
    "    Y_train, Y_test = Y[:split], Y[split:]\n",
    "    Y_trains.append(Y_train)\n",
    "    Y_tests.append(Y_test)\n",
    "\n",
    "models = []\n",
    "for horizon, Y_train in zip(horizons, Y_trains):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(30, return_sequences=True, input_shape=(window_size, 1)))\n",
    "    model.add(LSTM(30))\n",
    "    model.add(Dense(horizon))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(X_train, Y_train, epochs=50, batch_size=32)\n",
    "    models.append(model)\n",
    "\n",
    "for horizon, model in zip(horizons, models):\n",
    "    model.save(f'lstm_model_{horizon}.h5')\n",
    "\n",
    "Y_preds = []\n",
    "for model in models:\n",
    "    Y_pred = model.predict(X_test)\n",
    "    Y_preds.append(Y_pred)\n",
    "\n",
    "time_periods = [ # last 4 months of 2022\n",
    "    ('2022-01-01', '2022-12-01') # last 12 months of 2022\n",
    "]\n",
    "input_seqs = []\n",
    "for start_date, end_date in time_periods:\n",
    "    start_idx = df.index.get_loc(start_date) - window_size\n",
    "    end_idx = df.index.get_loc(end_date)\n",
    "    if start_idx < 0:\n",
    "        print(f'Not enough data for date range {start_date} to {end_date}')\n",
    "        continue\n",
    "    input_seq = scaled_data[start_idx:end_idx][-window_size:, 0]\n",
    "    input_seq = input_seq.reshape((1, window_size, 1))\n",
    "    input_seqs.append(input_seq)\n",
    "\n",
    "\n",
    "models = []\n",
    "for horizon in horizons:\n",
    "    model = load_model(f'lstm_model_{horizon}.h5')\n",
    "    models.append(model)\n",
    "\n",
    "Y_preds = []\n",
    "for input_seq in input_seqs:\n",
    "    y_preds = []\n",
    "    for model in models:\n",
    "        y_pred = model.predict(input_seq)\n",
    "        y_preds.append(y_pred)\n",
    "    Y_preds.append(y_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1115,
   "id": "e829a5f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([912703.08411121, 872868.99313331, 852646.55077457, 804472.92539477,\n",
       "       939069.82988119, 885985.50927639, 856229.59941626, 909245.51004171,\n",
       "       935702.24228501, 943361.15479469, 935296.23952508, 957726.74396634])"
      ]
     },
     "execution_count": 1115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_2022_ms_RS = Y_preds[0][0].reshape((-1, 1))\n",
    "y_pred_orig_2022_ms = np.zeros((len(y_pred_2022_ms_RS), df.shape[1]))\n",
    "y_pred_orig_2022_ms[:, 0] = y_pred_2022_ms_RS[:, 0]\n",
    "y_pred_orig_2022_ms = scaler.inverse_transform(y_pred_orig_2022_ms)[:, 0]\n",
    "y_pred_orig_2022_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1363,
   "id": "c95911b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 2s 27ms/step - loss: 0.2173\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1504\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0950\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0471\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0255\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0207\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0111\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0115\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0148\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0124\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0081\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0066\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0072\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0072\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0067\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0063\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0061\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0058\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0058\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0059\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0057\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0059\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0057\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0056\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0058\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0058\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0056\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0057\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0057\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0057\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0056\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0056\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0056\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0057\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0057\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0057\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0057\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0056\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0057\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0057\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0056\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0057\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0056\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0056\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0056\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0056\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0056\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0056\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0056\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0056\n",
      "1/1 [==============================] - 1s 611ms/step\n",
      "1/1 [==============================] - 1s 536ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "df = pd.read_csv('lstm_data.csv', index_col='Month', parse_dates=True)\n",
    "df = df[['Median Price']]   \n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "\n",
    "window_size = 24\n",
    "horizons = [3]\n",
    "\n",
    "X, Ys = [], [[] for _ in horizons]\n",
    "for i in range(window_size, len(scaled_data) - max(horizons)):\n",
    "    X.append(scaled_data[i-window_size:i, 0])\n",
    "    for j, horizon in enumerate(horizons):\n",
    "        Ys[j].append(scaled_data[i:i+horizon, 0])\n",
    "X = np.array(X)\n",
    "Ys = [np.array(Y) for Y in Ys]\n",
    "X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "Y_trains, Y_tests = [], []\n",
    "for Y in Ys:\n",
    "    Y_train, Y_test = Y[:split], Y[split:]\n",
    "    Y_trains.append(Y_train)\n",
    "    Y_tests.append(Y_test)\n",
    "\n",
    "models = []\n",
    "for horizon, Y_train in zip(horizons, Y_trains):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(40, return_sequences=True, input_shape=(window_size, 1)))\n",
    "    model.add(LSTM(40))\n",
    "    model.add(Dense(horizon))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(X_train, Y_train, epochs=50, batch_size=32)\n",
    "    models.append(model)\n",
    "\n",
    "for horizon, model in zip(horizons, models):\n",
    "    model.save(f'lstm_model_{horizon}.h5')\n",
    "\n",
    "Y_preds = []\n",
    "for model in models:\n",
    "    Y_pred = model.predict(X_test)\n",
    "    Y_preds.append(Y_pred)\n",
    "\n",
    "time_periods = [ \n",
    "    ('2022-01-01', '2022-03-01'), \n",
    "    ('2022-04-01', '2022-06-01'), \n",
    "    ('2022-07-01', '2022-09-01'), \n",
    "    ('2022-10-01', '2022-12-01')\n",
    "]\n",
    "input_seqs = []\n",
    "for start_date, end_date in time_periods:\n",
    "    start_idx = df.index.get_loc(start_date) - window_size\n",
    "    end_idx = df.index.get_loc(end_date)\n",
    "    if start_idx < 0:\n",
    "        print(f'Not enough data for date range {start_date} to {end_date}')\n",
    "        continue\n",
    "    input_seq = scaled_data[start_idx:end_idx][-window_size:, 0]\n",
    "    input_seq = input_seq.reshape((1, window_size, 1))\n",
    "    input_seqs.append(input_seq)\n",
    "\n",
    "\n",
    "models = []\n",
    "for horizon in horizons:\n",
    "    model = load_model(f'lstm_model_{horizon}.h5')\n",
    "    models.append(model)\n",
    "\n",
    "Y_preds = []\n",
    "for input_seq in input_seqs:\n",
    "    y_preds = []\n",
    "    for model in models:\n",
    "        y_pred = model.predict(input_seq)\n",
    "        y_preds.append(y_pred)\n",
    "    Y_preds.append(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1342,
   "id": "378b7498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([865057.49192834, 868126.11508369, 871868.60692501])"
      ]
     },
     "execution_count": 1342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict Q1 2022 MS no X \n",
    "start_date = '2022-01-01'\n",
    "end_date = '2022-03-01'\n",
    "dates = pd.date_range(start_date, end_date, freq='MS')\n",
    "X = []\n",
    "for date in dates:\n",
    "    past_data = df.loc[date - pd.DateOffset(months=window_size):date - pd.DateOffset(months=1)]\n",
    "    past_data = scaler.transform(past_data)\n",
    "    X.append(past_data)\n",
    "X = np.array(X)\n",
    "y_pred_2022Q1 = model.predict(X)\n",
    "y_pred_orig_2022Q1 = np.zeros((len(y_pred_2022Q1), df.shape[1]))\n",
    "y_pred_orig_2022Q1[:, 0] = y_pred_2022Q1[:, 0]\n",
    "y_pred_orig_2022Q1 = scaler.inverse_transform(y_pred_orig_2022Q1)[:, 0]\n",
    "y_pred_orig_2022Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1341,
   "id": "4561554f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([876960.92963219, 883673.21145535, 890876.04618072])"
      ]
     },
     "execution_count": 1341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict Q2 2022 MS no X \n",
    "start_date = '2022-04-01'\n",
    "end_date = '2022-06-01'\n",
    "dates = pd.date_range(start_date, end_date, freq='MS')\n",
    "X = []\n",
    "for date in dates:\n",
    "    past_data = df.loc[date - pd.DateOffset(months=window_size):date - pd.DateOffset(months=1)]\n",
    "    past_data = scaler.transform(past_data)\n",
    "    X.append(past_data)\n",
    "X = np.array(X)\n",
    "y_pred_2022Q2 = model.predict(X)\n",
    "y_pred_orig_2022Q2 = np.zeros((len(y_pred_2022Q2), df.shape[1]))\n",
    "y_pred_orig_2022Q2[:, 0] = y_pred_2022Q2[:, 0]\n",
    "y_pred_orig_2022Q2 = scaler.inverse_transform(y_pred_orig_2022Q2)[:, 0]\n",
    "y_pred_orig_2022Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1340,
   "id": "e755bf52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([897555.20352721, 902857.98990726, 906591.63504839])"
      ]
     },
     "execution_count": 1340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict Q3 2022 MS no X \n",
    "start_date = '2022-07-01'\n",
    "end_date = '2022-09-01'\n",
    "dates = pd.date_range(start_date, end_date, freq='MS')\n",
    "X = []\n",
    "for date in dates:\n",
    "    past_data = df.loc[date - pd.DateOffset(months=window_size):date - pd.DateOffset(months=1)]\n",
    "    past_data = scaler.transform(past_data)\n",
    "    X.append(past_data)\n",
    "X = np.array(X)\n",
    "y_pred_2022Q3 = model.predict(X)\n",
    "y_pred_orig_2022Q3 = np.zeros((len(y_pred_2022Q3), df.shape[1]))\n",
    "y_pred_orig_2022Q3[:, 0] = y_pred_2022Q3[:, 0]\n",
    "y_pred_orig_2022Q3 = scaler.inverse_transform(y_pred_orig_2022Q3)[:, 0]\n",
    "y_pred_orig_2022Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1364,
   "id": "19eca9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([913003.29789519, 915404.13025022, 917106.98497295])"
      ]
     },
     "execution_count": 1364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict Q4 2022 MS no X \n",
    "start_date = '2022-10-01'\n",
    "end_date = '2022-12-01'\n",
    "dates = pd.date_range(start_date, end_date, freq='MS')\n",
    "X = []\n",
    "for date in dates:\n",
    "    past_data = df.loc[date - pd.DateOffset(months=window_size):date - pd.DateOffset(months=1)]\n",
    "    past_data = scaler.transform(past_data)\n",
    "    X.append(past_data)\n",
    "X = np.array(X)\n",
    "y_pred_2022Q4 = model.predict(X)\n",
    "y_pred_orig_2022Q4 = np.zeros((len(y_pred_2022Q4), df.shape[1]))\n",
    "y_pred_orig_2022Q4[:, 0] = y_pred_2022Q4[:, 0]\n",
    "y_pred_orig_2022Q4 = scaler.inverse_transform(y_pred_orig_2022Q4)[:, 0]\n",
    "y_pred_orig_2022Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "id": "4b0cd818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 2s 52ms/step - loss: 0.3373\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.3165\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2964\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.2761\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2534\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2281\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1987\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1649\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1290\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0911\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0640\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0488\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0368\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0243\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0169\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0168\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0185\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0183\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0160\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0130\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0111\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0107\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0107\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0102\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0097\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0092\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0091\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0088\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0084\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0081\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0078\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0076\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0074\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0071\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0069\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0068\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0067\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0066\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0065\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0064\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0063\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0062\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0061\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0060\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0060\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0059\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0059\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0058\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0058\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0058\n",
      "1/1 [==============================] - 1s 562ms/step\n",
      "1/1 [==============================] - 1s 531ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "df = pd.read_csv('lstm_data.csv', index_col='Month', parse_dates=True)\n",
    "df = df[['Median Price']]   \n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "\n",
    "window_size = 48\n",
    "horizons = [12]\n",
    "\n",
    "X, Ys = [], [[] for _ in horizons]\n",
    "for i in range(window_size, len(scaled_data) - max(horizons)):\n",
    "    X.append(scaled_data[i-window_size:i, 0])\n",
    "    for j, horizon in enumerate(horizons):\n",
    "        Ys[j].append(scaled_data[i:i+horizon, 0])\n",
    "X = np.array(X)\n",
    "Ys = [np.array(Y) for Y in Ys]\n",
    "X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "Y_trains, Y_tests = [], []\n",
    "for Y in Ys:\n",
    "    Y_train, Y_test = Y[:split], Y[split:]\n",
    "    Y_trains.append(Y_train)\n",
    "    Y_tests.append(Y_test)\n",
    "\n",
    "models = []\n",
    "for horizon, Y_train in zip(horizons, Y_trains):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(30, return_sequences=True, input_shape=(window_size, 1)))\n",
    "    model.add(LSTM(30))\n",
    "    model.add(Dense(horizon))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(X_train, Y_train, epochs=50, batch_size=32)\n",
    "    models.append(model)\n",
    "\n",
    "for horizon, model in zip(horizons, models):\n",
    "    model.save(f'lstm_model_{horizon}.h5')\n",
    "\n",
    "Y_preds = []\n",
    "for model in models:\n",
    "    Y_pred = model.predict(X_test)\n",
    "    Y_preds.append(Y_pred)\n",
    "\n",
    "time_periods = [ # last 4 months of 2022\n",
    "    ('2021-01-01', '2021-12-01') # last 12 months of 2022\n",
    "]\n",
    "input_seqs = []\n",
    "for start_date, end_date in time_periods:\n",
    "    start_idx = df.index.get_loc(start_date) - window_size\n",
    "    end_idx = df.index.get_loc(end_date)\n",
    "    if start_idx < 0:\n",
    "        print(f'Not enough data for date range {start_date} to {end_date}')\n",
    "        continue\n",
    "    input_seq = scaled_data[start_idx:end_idx][-window_size:, 0]\n",
    "    input_seq = input_seq.reshape((1, window_size, 1))\n",
    "    input_seqs.append(input_seq)\n",
    "\n",
    "\n",
    "models = []\n",
    "for horizon in horizons:\n",
    "    model = load_model(f'lstm_model_{horizon}.h5')\n",
    "    models.append(model)\n",
    "\n",
    "Y_preds = []\n",
    "for input_seq in input_seqs:\n",
    "    y_preds = []\n",
    "    for model in models:\n",
    "        y_pred = model.predict(input_seq)\n",
    "        y_preds.append(y_pred)\n",
    "    Y_preds.append(y_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1078,
   "id": "dfb792e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([823573.66019487, 844054.31139469, 853517.78191328, 818997.65387177,\n",
       "       856268.02515984, 860662.57283092, 884860.35758257, 869345.2038765 ,\n",
       "       899726.08920932, 874294.76380348, 887428.97334695, 845793.59966516])"
      ]
     },
     "execution_count": 1078,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_2021_ms_RS = Y_preds[0][0].reshape((-1, 1))\n",
    "y_pred_orig_2021_ms = np.zeros((len(y_pred_2021_ms_RS), df.shape[1]))\n",
    "y_pred_orig_2021_ms[:, 0] = y_pred_2021_ms_RS[:, 0]\n",
    "y_pred_orig_2021_ms = scaler.inverse_transform(y_pred_orig_2021_ms)[:, 0]\n",
    "y_pred_orig_2021_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1304,
   "id": "cd46401f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 2s 35ms/step - loss: 0.2059\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1509\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0979\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0422\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0116\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0313\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0166\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0086\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0134\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0144\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0111\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0079\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0077\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0083\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0076\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0066\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0070\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0068\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0063\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0061\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0062\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0061\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0058\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0057\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0056\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0057\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0057\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0057\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0056\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0056\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0056\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0056\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0056\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0057\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0056\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0056\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0057\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0056\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0057\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0057\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0056\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0057\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0057\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0056\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0056\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0056\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0056\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0056\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0056\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0056\n",
      "1/1 [==============================] - 1s 560ms/step\n",
      "1/1 [==============================] - 1s 513ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "df = pd.read_csv('lstm_data.csv', index_col='Month', parse_dates=True)\n",
    "df = df[['Median Price']]   \n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "\n",
    "window_size = 24\n",
    "horizons = [3]\n",
    "\n",
    "X, Ys = [], [[] for _ in horizons]\n",
    "for i in range(window_size, len(scaled_data) - max(horizons)):\n",
    "    X.append(scaled_data[i-window_size:i, 0])\n",
    "    for j, horizon in enumerate(horizons):\n",
    "        Ys[j].append(scaled_data[i:i+horizon, 0])\n",
    "X = np.array(X)\n",
    "Ys = [np.array(Y) for Y in Ys]\n",
    "X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "Y_trains, Y_tests = [], []\n",
    "for Y in Ys:\n",
    "    Y_train, Y_test = Y[:split], Y[split:]\n",
    "    Y_trains.append(Y_train)\n",
    "    Y_tests.append(Y_test)\n",
    "\n",
    "models = []\n",
    "for horizon, Y_train in zip(horizons, Y_trains):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(40, return_sequences=True, input_shape=(window_size, 1)))\n",
    "    model.add(LSTM(40))\n",
    "    model.add(Dense(horizon))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(X_train, Y_train, epochs=50, batch_size=32)\n",
    "    models.append(model)\n",
    "\n",
    "for horizon, model in zip(horizons, models):\n",
    "    model.save(f'lstm_model_{horizon}.h5')\n",
    "\n",
    "Y_preds = []\n",
    "for model in models:\n",
    "    Y_pred = model.predict(X_test)\n",
    "    Y_preds.append(Y_pred)\n",
    "\n",
    "time_periods = [ \n",
    "    ('2021-01-01', '2021-03-01'), \n",
    "    ('2021-04-01', '2021-06-01'), \n",
    "    ('2021-07-01', '2021-09-01'), \n",
    "    ('2021-10-01', '2021-12-01')\n",
    "]\n",
    "input_seqs = []\n",
    "for start_date, end_date in time_periods:\n",
    "    start_idx = df.index.get_loc(start_date) - window_size\n",
    "    end_idx = df.index.get_loc(end_date)\n",
    "    if start_idx < 0:\n",
    "        print(f'Not enough data for date range {start_date} to {end_date}')\n",
    "        continue\n",
    "    input_seq = scaled_data[start_idx:end_idx][-window_size:, 0]\n",
    "    input_seq = input_seq.reshape((1, window_size, 1))\n",
    "    input_seqs.append(input_seq)\n",
    "\n",
    "\n",
    "models = []\n",
    "for horizon in horizons:\n",
    "    model = load_model(f'lstm_model_{horizon}.h5')\n",
    "    models.append(model)\n",
    "\n",
    "Y_preds = []\n",
    "for input_seq in input_seqs:\n",
    "    y_preds = []\n",
    "    for model in models:\n",
    "        y_pred = model.predict(input_seq)\n",
    "        y_preds.append(y_pred)\n",
    "    Y_preds.append(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1181,
   "id": "56ec7be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([809673.06303978, 806928.28989029, 810681.11413717])"
      ]
     },
     "execution_count": 1181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2021 Q1 no X\n",
    "y_pred_2021Q1_ms_RS = Y_preds[0][0].reshape((-1, 1))\n",
    "y_pred_orig_2021Q1_ms = np.zeros((len(y_pred_2021Q1_ms_RS), df.shape[1]))\n",
    "y_pred_orig_2021Q1_ms[:, 0] = y_pred_2021Q1_ms_RS[:, 0]\n",
    "y_pred_orig_2021Q1_ms = scaler.inverse_transform(y_pred_orig_2021Q1_ms)[:, 0]\n",
    "y_pred_orig_2021Q1_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1231,
   "id": "9a3c1c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([813242.77409911, 816646.25498652, 820300.24605989])"
      ]
     },
     "execution_count": 1231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2021 Q2 no X\n",
    "y_pred_2021Q2_ms_RS = Y_preds[1][0].reshape((-1, 1))\n",
    "y_pred_orig_2021Q2_ms = np.zeros((len(y_pred_2021Q2_ms_RS), df.shape[1]))\n",
    "y_pred_orig_2021Q2_ms[:, 0] = y_pred_2021Q2_ms_RS[:, 0]\n",
    "y_pred_orig_2021Q2_ms = scaler.inverse_transform(y_pred_orig_2021Q2_ms)[:, 0]\n",
    "y_pred_orig_2021Q2_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1156,
   "id": "2273826a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([821705.65581322, 828582.78340101, 823924.69185591])"
      ]
     },
     "execution_count": 1156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2021 Q3 no X\n",
    "y_pred_2021Q3_ms_RS = Y_preds[2][0].reshape((-1, 1))\n",
    "y_pred_orig_2021Q3_ms = np.zeros((len(y_pred_2021Q3_ms_RS), df.shape[1]))\n",
    "y_pred_orig_2021Q3_ms[:, 0] = y_pred_2021Q3_ms_RS[:, 0]\n",
    "y_pred_orig_2021Q3_ms = scaler.inverse_transform(y_pred_orig_2021Q3_ms)[:, 0]\n",
    "y_pred_orig_2021Q3_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1305,
   "id": "5c8c3dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([860948.16592336, 864901.08767152, 865208.45985413])"
      ]
     },
     "execution_count": 1305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2021 Q4 no X\n",
    "y_pred_2021Q4_ms_RS = Y_preds[3][0].reshape((-1, 1))\n",
    "y_pred_orig_2021Q4_ms = np.zeros((len(y_pred_2021Q4_ms_RS), df.shape[1]))\n",
    "y_pred_orig_2021Q4_ms[:, 0] = y_pred_2021Q4_ms_RS[:, 0]\n",
    "y_pred_orig_2021Q4_ms = scaler.inverse_transform(y_pred_orig_2021Q4_ms)[:, 0]\n",
    "y_pred_orig_2021Q4_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "id": "b2fee96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 3s 51ms/step - loss: 0.3373\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.3144\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.2923\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.2699\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2447\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.2169\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1854\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1508\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1155\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0803\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0568\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0447\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0357\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0278\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0225\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0187\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0156\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0132\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0120\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0121\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0127\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0129\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0124\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0116\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0107\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0100\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0095\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0090\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0086\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0082\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0079\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0076\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0074\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0072\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0070\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0069\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0067\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0066\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0064\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0063\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0062\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0061\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0060\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0060\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0059\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0059\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0058\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0058\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0058\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0058\n",
      "1/1 [==============================] - 1s 507ms/step\n",
      "1/1 [==============================] - 0s 477ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "df = pd.read_csv('lstm_data.csv', index_col='Month', parse_dates=True)\n",
    "df = df[['Median Price']]   \n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "\n",
    "window_size = 48\n",
    "horizons = [12]\n",
    "\n",
    "X, Ys = [], [[] for _ in horizons]\n",
    "for i in range(window_size, len(scaled_data) - max(horizons)):\n",
    "    X.append(scaled_data[i-window_size:i, 0])\n",
    "    for j, horizon in enumerate(horizons):\n",
    "        Ys[j].append(scaled_data[i:i+horizon, 0])\n",
    "X = np.array(X)\n",
    "Ys = [np.array(Y) for Y in Ys]\n",
    "X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "Y_trains, Y_tests = [], []\n",
    "for Y in Ys:\n",
    "    Y_train, Y_test = Y[:split], Y[split:]\n",
    "    Y_trains.append(Y_train)\n",
    "    Y_tests.append(Y_test)\n",
    "\n",
    "models = []\n",
    "for horizon, Y_train in zip(horizons, Y_trains):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(30, return_sequences=True, input_shape=(window_size, 1)))\n",
    "    model.add(LSTM(30))\n",
    "    model.add(Dense(horizon))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(X_train, Y_train, epochs=50, batch_size=32)\n",
    "    models.append(model)\n",
    "\n",
    "for horizon, model in zip(horizons, models):\n",
    "    model.save(f'lstm_model_{horizon}.h5')\n",
    "\n",
    "Y_preds = []\n",
    "for model in models:\n",
    "    Y_pred = model.predict(X_test)\n",
    "    Y_preds.append(Y_pred)\n",
    "\n",
    "time_periods = [ # last 4 months of 2022\n",
    "    ('2021-01-01', '2021-12-01') # last 12 months of 2022\n",
    "]\n",
    "input_seqs = []\n",
    "for start_date, end_date in time_periods:\n",
    "    start_idx = df.index.get_loc(start_date) - window_size\n",
    "    end_idx = df.index.get_loc(end_date)\n",
    "    if start_idx < 0:\n",
    "        print(f'Not enough data for date range {start_date} to {end_date}')\n",
    "        continue\n",
    "    input_seq = scaled_data[start_idx:end_idx][-window_size:, 0]\n",
    "    input_seq = input_seq.reshape((1, window_size, 1))\n",
    "    input_seqs.append(input_seq)\n",
    "\n",
    "\n",
    "models = []\n",
    "for horizon in horizons:\n",
    "    model = load_model(f'lstm_model_{horizon}.h5')\n",
    "    models.append(model)\n",
    "\n",
    "Y_preds = []\n",
    "for input_seq in input_seqs:\n",
    "    y_preds = []\n",
    "    for model in models:\n",
    "        y_pred = model.predict(input_seq)\n",
    "        y_preds.append(y_pred)\n",
    "    Y_preds.append(y_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "id": "20e9fc3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([817249.1812408 , 846872.69449234, 846811.64550781, 818615.82759023,\n",
       "       851745.60552835, 883259.10484791, 844436.10391021, 863149.94752407,\n",
       "       867777.1769166 , 876298.00114036, 875310.98628044, 907443.18059087])"
      ]
     },
     "execution_count": 1053,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_2020_ms_RS = Y_preds[0][0].reshape((-1, 1))\n",
    "y_pred_orig_2020_ms = np.zeros((len(y_pred_2020_ms_RS), df.shape[1]))\n",
    "y_pred_orig_2020_ms[:, 0] = y_pred_2020_ms_RS[:, 0]\n",
    "y_pred_orig_2020_ms = scaler.inverse_transform(y_pred_orig_2020_ms)[:, 0]\n",
    "y_pred_orig_2020_ms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111286ce",
   "metadata": {},
   "source": [
    "# END "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb72320",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
